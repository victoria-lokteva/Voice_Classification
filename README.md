В репозитории представлен классификатор мужских и женских голосов на базе фреймворка PyTorch.


## Данные

Использовался датасет Libritts (train-clean-100), который содержит 33236 записей мужских и женских голосов с частотой дискретизации 24000 Гц.


## Модель

Аудиоданные были превращены в мел-спектрограммы, после чего они обрабатывались уже как картинки. 
Для классификации использовалась небольшая CNN с Dilated Convolutions. 

Для запуска нуно запустить скрипт main.py, также понадобится файл speakers.tsv

## Результаты

Модель обучалась в Google Colab на GPU.

Построенная архитектура оказалась неудачной, сходимость у нее слишком медленная, поэтому достичь положительных результатов не удалось. При обучении на 62 эпохах точность почти не отличалась от случайного классификатора (однако функция потерь все же уменьшалась и на тренировочной, и на тестовой выборке с течением времени). Также огромный недостаток модели, что даже на GPU скорость обучения крайне медленная, и это не позволяет провести подбор гиперпараметров за разумное время.

## Что нужно сделать еще?

- Попробовать сделать топологию пространства менне сложной, например, добавить residiual connections. Возможно, это ускорит сходимость.
- В качестве оптимизатора попробовать градиентный спуск с моментом (так как он иногда дает очень хорошие результаты). Однако он требует уже тщательной настройки параметров, в отличие от Adam, поэтому первым делом нужно добиться ускорения обучения
- Аугментрировать данные, например, добавить шум в аудиодорожки или добавить паузы в запись
- Побробовать обучить другие модели: например,  предобученную на ImageNet Inception_v3
- Интересно было бы попробовать совсем другой подход -- не считать спектрограммы частот, а работать с изначальными временными данными (зависимостью амплитуды от времени). К таким данным можно применять одномерные свертки. 
